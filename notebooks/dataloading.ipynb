{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloading experiments\n",
    "\n",
    "This notebook is for experimenting with different dataloading implementations and strategies.\n",
    "\n",
    "Some requirements:\n",
    "\n",
    "- working with very large datasets of text (100s of GBs) split across multiple files\n",
    "- need to be able to load data in distributed training across multiple GPUs (i.e. each GPU sees non-overlapping portion of the data)\n",
    "- need to be able to load batches of data (i.e. [batch_size, seq_len])\n",
    "- need to be able to load data in a streaming fashion, so that the whole dataset doesn't need to fit into memory at once\n",
    "- needs to include tokenization\n",
    "\n",
    "Desired properties:\n",
    "\n",
    "- fast\n",
    "- memory efficient\n",
    "- minimizes time spent loading data, so that the GPU is never waiting for the data to load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface Dataset with Pytorch IterableDataset and DataLoader\n",
    "\n",
    "Since we alread use huggingface to get our datasets, let's try using huggingface's Dataset in combination with Pytorch's DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gollem.data.common import DATA_CACHE_DIR\n",
    "from gollem.tokenizer import get_tokenizer\n",
    "\n",
    "tinystories_dataset_id = \"roneneldan/Tinystories\"\n",
    "tinystories_ds_path = DATA_CACHE_DIR / \"tinystories\" / \"TinyStories_all_data\"\n",
    "\n",
    "tokenizer = get_tokenizer(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5782ff4885c64abda2486828de9ce107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description \n",
      "citation \n",
      "homepage \n",
      "license \n",
      "features {'story': Value(dtype='string', id=None), 'instruction': {'features': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'prompt:': Value(dtype='string', id=None), 'words': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, 'summary': Value(dtype='string', id=None), 'source': Value(dtype='string', id=None)}\n",
      "post_processed None\n",
      "supervised_keys None\n",
      "builder_name json\n",
      "dataset_name tiny_stories_all_data\n",
      "config_name default\n",
      "version 0.0.0\n",
      "splits {'train': SplitInfo(name='train', num_bytes=6519810584, num_examples=4967871, shard_lengths=[400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000, 167871], dataset_name='tiny_stories_all_data')}\n",
      "download_checksums {'/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data00.json': {'num_bytes': 140424235, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data01.json': {'num_bytes': 140372109, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data02.json': {'num_bytes': 140537677, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data03.json': {'num_bytes': 140385817, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data04.json': {'num_bytes': 140540961, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data05.json': {'num_bytes': 140488084, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data06.json': {'num_bytes': 140408938, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data07.json': {'num_bytes': 140404430, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data08.json': {'num_bytes': 140427706, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data09.json': {'num_bytes': 140362835, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data10.json': {'num_bytes': 140285669, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data11.json': {'num_bytes': 140272677, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data12.json': {'num_bytes': 140358544, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data13.json': {'num_bytes': 140443405, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data14.json': {'num_bytes': 140131319, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data15.json': {'num_bytes': 140207809, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data16.json': {'num_bytes': 140232125, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data17.json': {'num_bytes': 140391792, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data18.json': {'num_bytes': 140473361, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data19.json': {'num_bytes': 140457799, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data20.json': {'num_bytes': 140369466, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data21.json': {'num_bytes': 140361164, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data22.json': {'num_bytes': 140482260, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data23.json': {'num_bytes': 140261146, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data24.json': {'num_bytes': 140318712, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data25.json': {'num_bytes': 140307496, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data26.json': {'num_bytes': 140527914, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data27.json': {'num_bytes': 140218254, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data28.json': {'num_bytes': 140632203, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data29.json': {'num_bytes': 140579114, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data30.json': {'num_bytes': 140508953, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data31.json': {'num_bytes': 140387626, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data32.json': {'num_bytes': 140303087, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data33.json': {'num_bytes': 140258740, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data34.json': {'num_bytes': 140346123, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data35.json': {'num_bytes': 140433120, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data36.json': {'num_bytes': 140221415, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data37.json': {'num_bytes': 140284995, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data38.json': {'num_bytes': 140396597, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data39.json': {'num_bytes': 140328168, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data40.json': {'num_bytes': 140440381, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data41.json': {'num_bytes': 140292864, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data42.json': {'num_bytes': 140389279, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data43.json': {'num_bytes': 140357607, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data44.json': {'num_bytes': 140259023, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data45.json': {'num_bytes': 140417405, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data46.json': {'num_bytes': 140369034, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data47.json': {'num_bytes': 140413474, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data48.json': {'num_bytes': 140324357, 'checksum': None}, '/Users/jonathon/code/gollem/gollem/data/datasets/tinystories/TinyStories_all_data/data49.json': {'num_bytes': 95236458, 'checksum': None}}\n",
      "download_size 6973633727\n",
      "post_processing_size None\n",
      "dataset_size 6519810584\n",
      "size_in_bytes 13493444311\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "from datasets import IterableDataset\n",
    "\n",
    "ds_builder = load_dataset_builder(path=str(tinystories_ds_path))\n",
    "for k, v in ds_builder.info.__dict__.items():\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb3586f2889472b8d2716a859d03638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train']\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_split_names\n",
    "\n",
    "print(get_dataset_split_names(path=str(tinystories_ds_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88621f11fba149f785a000f1aa302601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "ds = load_dataset(path=str(tinystories_ds_path), split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['story', 'instruction', 'summary', 'source'],\n",
       "    num_rows: 4967871\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4967871"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986af86cb3c9406f910b5fb69e63f2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['story', 'instruction', 'summary', 'source']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import cast\n",
    "\n",
    "\n",
    "iter_ds = load_dataset(path=str(tinystories_ds_path), split=\"train\", streaming=True)\n",
    "iter_ds = cast(IterableDataset, iter_ds)\n",
    "iter_ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 37 (577354952.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 41\u001b[0;36m\u001b[0m\n\u001b[0;31m    for i, batch in enumerate(batched_ds):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 37\n"
     ]
    }
   ],
   "source": [
    "from typing import Generator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "iter_ds = cast(IterableDataset, iter_ds)\n",
    "# Strategy\n",
    "# 1. Use hugginface IterableDataset to load batches of examples\n",
    "# 2. tokenize each batch of examples on the fly\n",
    "# 3. concatenate tokens to get batch of seq_len tokens with no padding (collecting next batch of examples as necessary)\n",
    "# 4. repeat\n",
    "\n",
    "# Questions:\n",
    "# - how to make this work with distributed training?\n",
    "#    - can we customize the number of shards even if they are different from number of files?\n",
    "tokenizer = get_tokenizer(\"gpt2\")\n",
    "\n",
    "data_column = \"story\"\n",
    "# columns_to_remove = [c for c in iter_ds.column_names if c != data_column]\n",
    "\n",
    "\n",
    "def tokenize_batch(examples):\n",
    "    return {\"text\": tokenizer.encode_batch(examples[data_column])}\n",
    "\n",
    "\n",
    "# get batch from iter_ds\n",
    "processed_ds = iter_ds.map(\n",
    "    tokenize_batch, batched=True, batch_size=32, remove_columns=iter_ds.column_names\n",
    ")\n",
    "processed_ds = cast(IterableDataset, processed_ds)\n",
    "print(processed_ds)\n",
    "\n",
    "# get batch from batched_ds\n",
    "batched_ds = processed_ds.batch(batch_size=32)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "seq_len = 1024\n",
    "\n",
    "\n",
    "def get_batch() -> Generator[np.ndarray, None, None]:\n",
    "    buffer = [[] * batch_size]\n",
    "    current_batch = np.full((batch_size, seq_len), 0, dtype=np.long)\n",
    "    current_idxs = np.zeros(batch_size, dtype=np.int32)\n",
    "\n",
    "    for batch in batched_ds:\n",
    "        batch_lens = np.array([len(t) for t in batch[\"text\"]])\n",
    "        batch_idxs = seq_len - batch_lens\n",
    "        end_idxs = current_idxs\n",
    "\n",
    "        current_batch[current_idxs:end_idxs] = \n",
    "\n",
    "\n",
    "for i, batch in enumerate(batched_ds):\n",
    "    print(i, len(batch[\"text\"]))\n",
    "    if i == 33:\n",
    "        break\n",
    "\n",
    "# get batch from batched_ds\n",
    "print(batch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
